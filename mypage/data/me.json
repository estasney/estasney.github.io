{
  "basics": {
    "name": "Eric Stasney",
    "label": "HR Analyst / Developer",
    "image": "",
    "email": "",
    "phone": "",
    "url": "https://www.linkedin.com/in/eric-stasney-965962108",
    "summary": "Experienced data analyst leveraging a diverse background, self-taught programming and relentless drive. I enjoy a dynamic environment with new problems. I split problems into their sub-components, apply what I know and seek out what I do not. \n\nI love working with Python! My core skill set is ETL. Very comfortable with Selenium, Requests, Pandas, and Jupyter Notebooks, to name a few.\n\nI have also enjoyed creating data-driven web applications, Chrome Extensions, and \"Kaggling\"",
    "location": {
      "address": "",
      "postalCode": "NC 27529",
      "city": "Garner",
      "countryCode": "US",
      "region": "North Carolina"
    },
    "profiles": [
      {
        "network": "GitHub",
        "username": "estasney",
        "url": "https://github.com/estasney"
      },
      {
        "network": "LinkedIn",
        "username": "",
        "url": "https://www.linkedin.com/in/eric-stasney-965962108"
      },
      {
        "network": "Kaggle",
        "username": "estasney",
        "url": "https://www.kaggle.com/estasney"
      }
    ]
  },
  "work": [
    {
      "name": "Cisco",
      "location": "Raleigh, NC (Remote)",
      "description": "Talent Hub",
      "position": "HR Analyst / Developer",
      "url": "",
      "startDate": "Aug 2016",
      "endDate": "",
      "summary": "Talent Hub is a small team delivering critical talent pipelines in an ever-changing Talent Landscape.",
      "highlights": [
        "Fulfill Talent Intelligence requests by senior leadership. These requests involve fetching unstructured data from external sources, normalizing and generating insights. This provides an invaluable quantitative analysis for data-driven decisions.",
        "Developed a web scraper for internal use. Users perform extractions via the Chrome Extension and manage them via a web application written in Flask. This replaced the team's previous method of copy/pasting multiple text fields between browser tabs.",
        "Compiled a Company Name Disambiguation Python package. I found that 'in the wild' companies can have hundreds of name variants. This makes answering questions like, 'How many of X are from Y company?' extremely tedious. I used a directed graph data structure to represent a hierarchy of names where multiple uncommon names map to one common name.",
        "Audited Cisco's external job postings for formatting issues. Determined that 30% of job postings had major formatting issues such as literal newlines, visible HTML tags and visibly different font styles between paragraphs. Uncovered root cause to be an Excel spreadsheet that was being used as a templating engine for copy/pasting job descriptions.",
        "Generated an LDA Topic Model from current and historical Cisco job descriptions. Applied model to extract skill hierarchies from job descriptions and advised on their demand.",
        "Showcased data-driven approaches to 'sourcing' via another Flask web app. Users can search for related words and skills via word-embeddings, explore document concepts with D3.js graphs, and uncover optimal search strings based on TF-IDF"
      ]
    },
    {
      "name": "US Army / COARNG",
      "location": "Denver, CO",
      "description": "Military Police",
      "position": "E4 (Specialist)",
      "url": "",
      "startDate": "Nov 2013",
      "endDate": "Nov 2016",
      "summary": "Enlisted in CO Army National Guard with the intent to serve my community, part-time. However, after completing OSUT, my unit was activated to Federal Service (Active Duty) and I completed an 18-month deployment."
    }
  ],
  "education": [
    {
      "institution": "The University of Tennessee",
      "area": "Biochemistry, Cellular and Molecular Biology",
      "studyType": "Bachelors",
      "startDate": "2006",
      "endDate": "2011",
      "gpa": "3.5"
    }
  ],
  "awards": [
    {
      "title": "P2P Recognition",
      "date": "Multiple dates",
      "awarder": "Multiple peers and managers",
      "summary": "Consistently exceeding expectations"
    }
  ],
  "skills": [
    {
      "name": "Python",
      "level": "Advanced",
      "keywords": [
        "Pandas",
        "NumPy",
        "Requests",
        "Kivy",
        "Jupyter",
        "Gensim",
        "Sklearn",
        "NetworkX",
        "OOP",
        "Functional Programming"
      ]
    },
    {
      "name": "ETL",
      "level": "Master",
      "keywords": [
        "Selenium",
        "Requests",
        "pdfminer",
        "MySQL",
        "Regex",
        "Elasticsearch"
      ]
    },
    {
      "name": "Web Development",
      "level": "Intermediate",
      "keywords": [
        "Flask",
        "SQLAlchemy",
        "JavaScript",
        "MySQL",
        "Chrome Extension"
      ]
    }
  ],
  "skills_ul" : [
    "PyInstaller",
    "Elasticsearch",
    "SQL",
    "MySQL",
    "Kivy",
    "Jupyter"
  ],
  "interests": [
    {
      "name": "IoT & Robotics",
      "keywords": [
        "Raspberry Pi",
        "Arduino"
      ]
    },
    {
      "name": "Woodworking",
      "keywords": [
        "3d Models",
        "Project planning"
      ]
    }
  ],
  "projects": [
    {
      "name": "Percy",
      "description": "Sourcing as a Science",
      "highlights": [
        "2nd round selection in Cisco's Innovate Everywhere Challenge",
        "Given a body of text, uses Pagerank algorithm to identify central topics. The result is returned and displayed in a D3.js force-directed graph.",
        "Locates the 'most discriminating' words in a document by referencing domain specific word probabilities. Provides insights into building efficient and relevant searches.",
        "Showcases word embeddings with a 'This + That' page. E.g. (Hardware + Storage) returns SAN, Storage Area Networks, NAS, etc"
      ],
      "keywords": [
        "NLP",
        "Flask",
        "Word Embeddings",
        "D3.js",
        "Bootstrap"
      ],
      "startDate": "Jan 2017",
      "endDate": "",
      "url": "https://estasney.pythonanywhere.com",
      "roles": [
        "Individual Project"
      ],
      "entity": "",
      "type": "web application"
    },
    {
      "name": "Web Scraper",
      "description": "Web scraper for internal team use",
      "highlights": [
        "Scraper exists of two main components : a Chrome Extension and Web Application",
        "Tracks extractions and prevents usage over a limit set by an administrator",
        "Manages extraction target lists to fetch only unseen data",
        "Parses raw strings into structured data. Transforms data into spreadsheet form compatible with internal ATS."
      ]
    }
  ]
}
